{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS .ipynb MAKES THE ALL TRAIN, ALL TEST, ALL VAL FILES THAT ARE IN bfd_2AA-dummy\n",
    "\n",
    "### IMPORTS & SETUP ###\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from bgflow.utils import (\n",
    "    IndexBatchIterator,\n",
    ")\n",
    "from bgflow import (\n",
    "    DiffEqFlow,\n",
    "    MeanFreeNormalDistribution,\n",
    ")\n",
    "from tbg.models2 import EGNN_dynamics_transferable_MD\n",
    "from bgflow import BlackBoxDynamics, BruteForceEstimator\n",
    "import os\n",
    "import tqdm\n",
    "import mdtraj as md\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: CF\n",
      "From file: CF-traj-arrays.npz\n",
      "(9800, 34, 3)\n",
      "Processing file: CE\n",
      "From file: CE-traj-arrays.npz\n",
      "(9800, 29, 3)\n",
      "Processing file: CC\n",
      "From file: CC-traj-arrays.npz\n",
      "(9800, 25, 3)\n",
      "Processing file: AV\n",
      "From file: AV-traj-arrays.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9800, 29, 3)\n",
      "Processing file: CG\n",
      "From file: CG-traj-arrays.npz\n",
      "(9800, 21, 3)\n",
      "Processing file: CH\n",
      "From file: CH-traj-arrays.npz\n",
      "(9800, 31, 3)\n"
     ]
    }
   ],
   "source": [
    "role_string = 'val' # either test, train or val\n",
    "\n",
    "### Note to ben - just uncomment the following obvious lines\n",
    "\n",
    "# Define the directory path\n",
    "directory_path = f'/home/bfd21/rds/hpc-work/bfd_2AA-dummy/{role_string}/'\n",
    "data_dictionary = {}\n",
    "\n",
    "# Loop over files that end with \".npz\"\n",
    "for file_name in os.listdir(directory_path):\n",
    "    if file_name.endswith(\".npz\"):\n",
    "        AA_abbrev = file_name[:2]\n",
    "        print(f\"Processing file: {AA_abbrev}\")\n",
    "        print(f\"From file: {file_name}\")\n",
    "        \n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        MD_positions = np.load(file_path)['positions']\n",
    "\n",
    "        print(MD_positions.shape)\n",
    "\n",
    "        #for t in range(len(MD_positions)): # much slower than using regular numpy to ||ize, but fine for now. Will reconsider when time comes.\n",
    "        #    avg_position = np.mean(MD_positions[t], axis=0)\n",
    "        #    MD_positions[t] -= avg_position # places the particles' CoM at zero\n",
    "\n",
    "        #    MD_positions[t] /= scale_factor # scales distances down by a factor of 30 relative to the CoM\n",
    "        #    # hopefully this ameliorates the learning process\n",
    "\n",
    "        #    ### GENERATING UNIT VECTOR TO GET THE RANDOM ROTATION ON THE UNIT SPHERE ###\n",
    "        #    z = np.random.uniform(low=-1, high=1)\n",
    "\n",
    "        #    phi = np.arccos(z) # doesnt seem to be that necessary... may be able to avoid\n",
    "        #    theta = np.random.uniform(low = 0, high= 2 * np.pi)\n",
    "        #    a = np.random.uniform(low = 0, high= 2 * np.pi)\n",
    "\n",
    "        #    x = np.sqrt(1 - z ** 2) * np.cos(theta)\n",
    "        #    y = np.sqrt(1 - z ** 2) * np.sin(theta)\n",
    "\n",
    "        #    rot_Matrix = np.array([[np.cos(a) + (1 - np.cos(a)) * x**2, x * y * (1 - np.cos(a)) - z * np.sin(a), x * z * (1 - np.cos(a)) + y * np.sin(a)], \n",
    "        #                           [y * x * (1 - np.cos(a)) + z * np.sin(a), np.cos(a) + (1 - np.cos(a)) * y**2, y * z * (1 - np.cos(a)) - x * np.sin(a)], \n",
    "        #                           [z * x * (1 - np.cos(a)) - y * np.sin(a), z * y * (1 - np.cos(a)) + x * np.sin(a), np.cos(a) + (1 - np.cos(a)) * z**2],\n",
    "        #                           ])\n",
    "            \n",
    "        #    MD_positions[t] = MD_positions[t] @ rot_Matrix.T # check this, but it should be fine for now.\n",
    "\n",
    "        #starting_shape = MD_positions.shape\n",
    "        \n",
    "        #flattened_MD = MD_positions.reshape(starting_shape[0], -1)\n",
    "        \n",
    "        #data_dictionary[AA_abbrev] = flattened_MD\n",
    "\n",
    "# Define the path to save the .npy file\n",
    "#save_path = f'/home/bfd21/rds/hpc-work/bfd_2AA-dummy/bfd_dummy_all_{role_string}.npy'\n",
    "\n",
    "# Save the data_dictionary as a .npy file\n",
    "#np.save(save_path, data_dictionary, allow_pickle=True)\n",
    "\n",
    "#print(f\"Data dictionary saved successfully at {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_ben0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
