{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS & SETUP ###\n",
    "import numpy as np\n",
    "import mdtraj as md\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined parameters\n",
    "raw_directory_path = '/home/bfd21/rds/hpc-work/sample_macrocycle_md/raw/N-Cap2'  # Raw trajectory directory with .xtc files\n",
    "gro_file_path = '/home/bfd21/rds/hpc-work/sample_macrocycle_md/raw/simulation_prep/N-Cap2/9.gro'  # Path to the .gro file\n",
    "splits = {'train': 0.8, 'test': 0.1}  # Train, test, and val split\n",
    "equilibrium_frac = 0.2  # Fraction considered at equilibrium\n",
    "\n",
    "save_dir = '/home/bfd21/rds/hpc-work/sample_macrocycle_md/N-Cap2' # where to save the final, processed, data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting .gro file to .pdb...\n",
      "Saved PDB file to /home/bfd21/rds/hpc-work/sample_macrocycle_md/N-Cap2/system.pdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/999 [00:00<02:05,  7.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [06:01<00:00,  2.76it/s]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(save_dir, exist_ok=True)  # Ensure the save directory exists\n",
    "pdb_file_path = os.path.join(save_dir, 'system.pdb')  # Output PDB file path\n",
    "\n",
    "# Function to generate a random rotation matrix\n",
    "def random_rotation_matrix():\n",
    "    z = np.random.uniform(low=-1, high=1)\n",
    "    theta = np.random.uniform(low=0, high=2 * np.pi)\n",
    "    a = np.random.uniform(low=0, high=2 * np.pi)\n",
    "    \n",
    "    x = np.sqrt(1 - z ** 2) * np.cos(theta)\n",
    "    y = np.sqrt(1 - z ** 2) * np.sin(theta)\n",
    "\n",
    "    rot_matrix = np.array([\n",
    "        [np.cos(a) + (1 - np.cos(a)) * x**2, x * y * (1 - np.cos(a)) - z * np.sin(a), x * z * (1 - np.cos(a)) + y * np.sin(a)],\n",
    "        [y * x * (1 - np.cos(a)) + z * np.sin(a), np.cos(a) + (1 - np.cos(a)) * y**2, y * z * (1 - np.cos(a)) - x * np.sin(a)],\n",
    "        [z * x * (1 - np.cos(a)) - y * np.sin(a), z * y * (1 - np.cos(a)) + x * np.sin(a), np.cos(a) + (1 - np.cos(a)) * z**2],\n",
    "    ])\n",
    "    return rot_matrix\n",
    "\n",
    "# Step 1: Convert .gro file to .pdb\n",
    "print(\"Converting .gro file to .pdb...\")\n",
    "traj = md.load(gro_file_path)\n",
    "traj.save_pdb(pdb_file_path)\n",
    "print(f\"Saved PDB file to {pdb_file_path}\")\n",
    "\n",
    "# Step 2: Process .xtc files using the PDB topology\n",
    "all_data = []\n",
    "\n",
    "# Loop over .xtc files in the directory\n",
    "for file_name in tqdm.tqdm(os.listdir(raw_directory_path)):\n",
    "    if file_name.endswith(\".xtc\"):\n",
    "        file_path = os.path.join(raw_directory_path, file_name)\n",
    "        #print(f\"Processing file: {file_name}\")\n",
    "        \n",
    "        # Load trajectory data using PDB topology\n",
    "        traj = md.load(file_path, top=pdb_file_path)  # Load .xtc with PDB topology\n",
    "        MD_positions = traj.xyz  # Shape: (n_frames, n_atoms, 3)\n",
    "        num_frames = MD_positions.shape[0]\n",
    "        \n",
    "        # Select only equilibrium portion\n",
    "        start_idx = int((1 - equilibrium_frac) * num_frames)\n",
    "        MD_positions = MD_positions[start_idx:]  # Keep the last equilibrium_frac portion\n",
    "\n",
    "        # Process each frame: Center CoM and apply random rotation\n",
    "        for t in range(len(MD_positions)):\n",
    "            avg_position = np.mean(MD_positions[t], axis=0)  # Compute CoM\n",
    "            MD_positions[t] -= avg_position  # Center at CoM\n",
    "            rotation_matrix = random_rotation_matrix()  # Generate random rotation matrix\n",
    "            MD_positions[t] = MD_positions[t] @ rotation_matrix.T  # Apply rotation\n",
    "        \n",
    "        # Append processed positions (no flattening!)\n",
    "        all_data.append(MD_positions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processed data shape: (517409, 206, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:01<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train data to /home/bfd21/rds/hpc-work/sample_macrocycle_md/N-Cap2/processed_train.npy with shape (413927, 206, 3)\n",
      "Saved test data to /home/bfd21/rds/hpc-work/sample_macrocycle_md/N-Cap2/processed_test.npy with shape (51740, 206, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved val data to /home/bfd21/rds/hpc-work/sample_macrocycle_md/N-Cap2/processed_val.npy with shape (51742, 206, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all data\n",
    "all_data = np.concatenate(all_data, axis=0)  # Combine all processed data\n",
    "print(f\"Total processed data shape: {all_data.shape}\")  # Shape: (n_samples, n_atoms, 3)\n",
    "\n",
    "# Shuffle data\n",
    "np.random.shuffle(all_data)\n",
    "\n",
    "# Split data into train, test, and val\n",
    "train_frac = splits['train']\n",
    "test_frac = splits['test']\n",
    "val_frac = 1 - (train_frac + test_frac)\n",
    "\n",
    "num_samples = all_data.shape[0]\n",
    "train_end = int(train_frac * num_samples)\n",
    "test_end = train_end + int(test_frac * num_samples)\n",
    "\n",
    "train_data = all_data[:train_end]  # Shape: (train_samples, n_atoms, 3)\n",
    "test_data = all_data[train_end:test_end]  # Shape: (test_samples, n_atoms, 3)\n",
    "val_data = all_data[test_end:]  # Shape: (val_samples, n_atoms, 3)\n",
    "\n",
    "# Save the splits as .npz files\n",
    "split_data = {'train': train_data, 'test': test_data, 'val': val_data}\n",
    "for role, data in tqdm.tqdm(split_data.items()):\n",
    "    save_path = os.path.join(save_dir, f'processed_{role}.npy')\n",
    "    np.save(save_path, data)\n",
    "    print(f\"Saved {role} data to {save_path} with shape {data.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_ben0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
