{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import numpy as np\n",
    "import MDAnalysis as mda\n",
    "from MDAnalysis.analysis.dihedrals import Dihedral\n",
    "\n",
    "import mdtraj as md\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First Order of Business:** let's see if our conditioning consistantly picked the correct loss strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies_batches = [\n",
    "    f'/home/bfd21/rds/hpc-work/tbg/cyclization/jobs/l1-sample-Feb-13/conditioned-on-cyc/uncond-on-time/cond-cyc-unc-time-l1-inference_losses_selected_batch-{i}.pkl' for i in range(4)\n",
    "]\n",
    "\n",
    "strategies_list = []\n",
    "\n",
    "for batch_str in strategies_batches:\n",
    "    # Load from the file\n",
    "    with open(batch_str, \"rb\") as f:\n",
    "        loaded_list = dill.load(f)\n",
    "    \n",
    "    for j in loaded_list:\n",
    "        strategies_list.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in strategies_list:\n",
    "    if i == strategies_list[0]:\n",
    "        count += 1\n",
    "\n",
    "print(count) # per the below output, it picked the correct outcome every single time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nice! Now onto next objective:** We want to do PCA on the dihedral angles, maybe bond angles, on the generated samples, and compare where they lie in this PCA space to the raw validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mdtraj_trajectory(pdb_path, data_files):\n",
    "    \"\"\"\n",
    "    Loads a PDB file, infers bonds, processes NPZ and NPY files, and constructs an MDTraj trajectory.\n",
    "\n",
    "    Parameters:\n",
    "        pdb_path (str): Path to the PDB file.\n",
    "        data_files (list of str): List of paths to NPZ or NPY files containing sampled atomic positions.\n",
    "\n",
    "    Returns:\n",
    "        mdtraj.Trajectory: The generated trajectory with inferred bonds and centered coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load PDB and infer bonds\n",
    "    pdb = md.load(pdb_path)\n",
    "    pdb.topology.create_standard_bonds()  # Infer bonds based on atom types and residue connectivity\n",
    "    topology = pdb.topology\n",
    "\n",
    "    # Load and process generated samples\n",
    "    all_samples = []\n",
    "    for data_file in data_files:\n",
    "        file_extension = os.path.splitext(data_file)[1]\n",
    "\n",
    "        if file_extension == \".npz\":\n",
    "            data = np.load(data_file)\n",
    "            samples_np = data[\"samples_np\"]  # Extract the relevant array from NPZ\n",
    "        elif file_extension == \".npy\":\n",
    "            samples_np = np.load(data_file)  # Load directly from NPY\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {data_file}\")\n",
    "\n",
    "        # Reshape samples to match the number of atoms in the PDB\n",
    "        n_atoms = len(list(topology.atoms))\n",
    "        samples = samples_np.reshape(-1, n_atoms, 3)  # (n_frames, n_atoms, 3)\n",
    "        all_samples.append(samples)\n",
    "\n",
    "    # Combine all samples into a single array\n",
    "    all_samples = np.concatenate(all_samples, axis=0)\n",
    "\n",
    "    # Create an MDTraj trajectory with the inferred bonds\n",
    "    traj = md.Trajectory(\n",
    "        xyz=all_samples,  # Shape: (n_frames, n_atoms, 3)\n",
    "        topology=topology\n",
    "    )\n",
    "\n",
    "    # Center the trajectory around the origin\n",
    "    traj.center_coordinates()\n",
    "\n",
    "    return traj\n",
    "\n",
    "def compute_all_dihedrals(traj):\n",
    "    \"\"\"\n",
    "    Computes backbone (phi, psi, omega) and side-chain (chi1, chi2, chi3, chi4) dihedral angles \n",
    "    for all amino acids in the given trajectory.\n",
    "    \n",
    "    Parameters:\n",
    "        traj (mdtraj.Trajectory): MDTraj trajectory object.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing dihedral angles in degrees.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute backbone dihedral angles\n",
    "    phi_indices, phi_angles = md.compute_phi(traj)\n",
    "    psi_indices, psi_angles = md.compute_psi(traj)\n",
    "    omega_indices, omega_angles = md.compute_omega(traj)\n",
    "\n",
    "    # Compute side-chain chi angles (some may be empty depending on the peptide)\n",
    "    chi1_indices, chi1_angles = md.compute_chi1(traj)\n",
    "    chi2_indices, chi2_angles = md.compute_chi2(traj)\n",
    "    chi3_indices, chi3_angles = md.compute_chi3(traj)\n",
    "    chi4_indices, chi4_angles = md.compute_chi4(traj)\n",
    "\n",
    "    dihedral_angles = {\n",
    "        \"phi\": phi_angles,\n",
    "        \"psi\": psi_angles,\n",
    "        \"omega\": omega_angles,\n",
    "        \"chi1\": chi1_angles if chi1_angles.size else None,\n",
    "        \"chi2\": chi2_angles if chi2_angles.size else None,\n",
    "        \"chi3\": chi3_angles if chi3_angles.size else None,\n",
    "        \"chi4\": chi4_angles if chi4_angles.size else None,\n",
    "    }\n",
    "\n",
    "    return dihedral_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = generate_mdtraj_trajectory(pdb_path = '/home/bfd21/rds/hpc-work/data/MDM2-sample-binders/ligand-only/l1/ligand1.pdb', \n",
    "                                  data_files = [])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
